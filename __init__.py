import os
import sys
import sounddevice as sd
import numpy as np
import time
import re
import torch
import threading

from funasr import AutoModel
# from funasr.utils.postprocess_utils import rich_transcription_postprocess
from modelscope import snapshot_download
from scipy.io.wavfile import write
from datetime import datetime

now_dir = os.path.dirname(os.path.abspath(__file__))


# æ³¨å†ŒèŠ‚ç‚¹
class VoiceRecorderNode:
    CATEGORY = "fg/å½•éŸ³å·¥å…·"
    RETURN_TYPES = ("LIST",)
    RETURN_NAMES = ("file_path_list",)
    FUNCTION = "process_record"
    OUTPUT_NODE = True

    def __init__(self):
        self.save_dir = None

        # å½•éŸ³æ§åˆ¶å˜é‡
        self.is_recording = False
        self.audio_data = []
        self.audio_path = ""
        self.last_press_time = 0
        self.debounce_interval = 0.3  # ä¼˜åŒ–é˜²æŠ–æ—¶é—´

        # éŸ³é¢‘æµå¯¹è±¡
        self.stream = None
        self.fs = 44100  # å›ºå®šé‡‡æ ·ç‡

    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "folder": ("STRING", {"directory": True, "default": "./ComfyUI/temp"}),
                "wait_for_seconds": ("INT", {"default": 1, "min": 0, "max": 5}),
                "record_seconds": ("FLOAT", {"default": 5.0, "min": 1.0, "max": 360.0}),
                "remove_file": ("BOOLEAN", {"default": False})
            },
        }

    def process_record(self, folder, wait_for_seconds, record_seconds, remove_file):
        try:
            # åˆ›å»ºä¿å­˜ç›®å½•
            os.makedirs(folder, exist_ok=True)
            self.save_dir = folder

            # ç­‰å¾…å½•éŸ³æ—¶é•¿
            time.sleep(wait_for_seconds)

            # å¯åŠ¨ä¸€ä¸ªå®šæ—¶å™¨ï¼Œåœ¨10ç§’åè°ƒç”¨å‡½æ•°
            timer = threading.Timer(record_seconds, self.stop_recording)
            timer.start()

            self.start_recording()

            time.sleep(record_seconds + 1)

            return {
                "ui": {
                    "status": [self.audio_path],
                    "progress": [0.5]
                },
                "result": [self.audio_path]
            }
        except Exception as e:
            # return (None, f"é”™è¯¯: {str(e)}")
            return {"ui": {"error": "no record data"}, "result": "error"}
        finally:
            if remove_file:
                print('å‡†å¤‡åˆ é™¤éŸ³é¢‘æ–‡ä»¶')
                timer = threading.Timer(15, self.remove_audio_file)
                timer.start()
            else:
                self.audio_path = None

    def remove_audio_file(self):
        print("å¼€å§‹åˆ é™¤æ–‡ä»¶")
        os.remove(self.audio_path)
        self.audio_path = None

    # æ ¸å¿ƒå½•éŸ³æ§åˆ¶é€»è¾‘ --------------------------------------------------
    def start_recording(self):
        """ä¼˜åŒ–çš„å½•éŸ³å¯åŠ¨é€»è¾‘"""
        current_time = time.time()
        if (current_time - self.last_press_time) < self.debounce_interval:
            return

        if not self.is_recording:
            self.last_press_time = current_time
            self.is_recording = True
            self.audio_data = []
            print("ğŸ¤ å½•éŸ³å¼€å§‹...")

            # å¯åŠ¨éŸ³é¢‘æµ
            self.stream = sd.InputStream(
                samplerate=self.fs,
                channels=1,
                dtype='int16',
                blocksize=int(self.fs * 0.05),  # æ›´çµæ•çš„ä¸­æ–­å“åº”
                callback=self.audio_callback
            )
            self.stream.start()

    def stop_recording(self):
        """å³æ—¶åœæ­¢å½•éŸ³å¹¶ä¿å­˜"""
        if self.is_recording:
            print("â¹ æ­£åœ¨åœæ­¢å½•éŸ³...")
            self.is_recording = False

            # å…³é—­éŸ³é¢‘æµ
            if self.stream and self.stream.active:
                self.stream.stop()
                self.stream.close()

            # ä¿å­˜å½•éŸ³
            if len(self.audio_data) > 0:
                self.save_recording()
            # print("âœ… å½•éŸ³å·²ä¿å­˜")

    def audio_callback(self, indata, frames, time, status):
        """å®æ—¶éŸ³é¢‘å›è°ƒå‡½æ•°"""
        if self.is_recording:
            self.audio_data.append(indata.copy())

    # æ–‡ä»¶ä¿å­˜é€»è¾‘ ------------------------------------------------------
    def save_recording(self):
        """ä¼˜åŒ–çš„éŸ³é¢‘ä¿å­˜æ–¹æ³•"""
        try:
            # print('å¼€å§‹ä¿å­˜éŸ³é¢‘æ•°æ®...')
            full_recording = np.concatenate(self.audio_data, axis=0)

            # ç”Ÿæˆæ—¶é—´æˆ³
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = os.path.join(
                self.save_dir,
                f"recording_{timestamp}.wav"
            )

            write(filename, self.fs, full_recording)
            # print(f"ğŸ’¾ æ–‡ä»¶å·²ä¿å­˜åˆ°ï¼š{os.path.abspath(filename)}")
            print("âœ… å½•éŸ³å·²ä¿å­˜")

            self.audio_path = filename
        except Exception as e:
            print(f"ä¿å­˜å¤±è´¥: {str(e)}")


class STTNode:

    def __init__(self):
        self.model = None
        self.model_dir = None
        self.result_txt = None

    @classmethod
    def INPUT_TYPES(s):
        return {
            "required": {
                # "audio": ("AUDIO",),
                "audio_path": ("STRING",),
                "language": (["auto",  "zh", "en", "yue", "ja", "ko", "nospeech"], {
                    "default": "auto"
                }),
                "use_itn": ("BOOLEAN", {"default": True}),
                "batch_size_s": ("INT", {"default": 60, "min": 1, "max": 100}),
                "merge_vad": ("BOOLEAN", {"default": True}),
                "merge_length_s": ("INT", {"default": 15, "min": 1, "max": 30})
            }
        }

    RETURN_TYPES = ("LIST",)
    RETURN_NAMES = ("list_string",)
    FUNCTION = "generate"
    CATEGORY = "STT/SenseVoice"
    OUTPUT_NODE = True

    def generate(self, audio_path, language, use_itn, batch_size_s, merge_vad, merge_length_s):
        # ä½¿ç”¨ç¤ºä¾‹
        # comfyui_root = get_comfyui_root()
        comfyui_root = None
        print("ComfyUIæ ¹ç›®å½•:", comfyui_root)

        try:
            if comfyui_root is None:
                self.model_dir = "iic/SenseVoiceSmall"
                snapshot_download(model_id="iic/SenseVoiceSmall")
            else:
                self.model_dir = os.path.join(now_dir, "models", "checkpoints", "SenseVoiceSmall")
                snapshot_download(model_id="iic/SenseVoiceSmall", local_dir=self.model_dir)

            if self.model is None:
                self.model = AutoModel(
                    model=self.model_dir,
                    trust_remote_code=True,
                    # remote_code="./model.py",
                    vad_model="fsmn-vad",
                    vad_kwargs={"max_single_segment_time": 30000},
                    disable_update=True,
                    device="cuda:0",
                )

                # print(f"æ¨¡å‹åŠ è½½æˆåŠŸ--{audio_path}")

            res = self.model.generate(
                input=audio_path,
                cache={},
                language=language,  # "zh", "en", "yue", "ja", "ko", "nospeech"
                use_itn=use_itn,
                batch_size_s=batch_size_s,
                merge_vad=merge_vad,
                merge_length_s=merge_length_s,
            )

            self.result_txt = re.sub(r'<\|.*?\|>', '', res[0]["text"])
            # print(text)

            return [self.result_txt]
        except Exception as e:
            print(f"sensevoiceæ¨ç†å¼‚å¸¸: {str(e)}")
            pass
        finally:
            self.result_txt = None

# class ShowTextNode:
#     @classmethod
#     def INPUT_TYPES(s):
#         return {
#             "required": {
#                 "sense_voice_output":("TEXT",),
#                 "text": ("STRING", {"multiline": True, "dynamicPrompts": True}),
#             }
#         }
#     RETURN_TYPES = ()
#     FUNCTION = "encode"
#     OUTPUT_NODE = True
#     CATEGORY = "AIFSH_SenseVoice"
#
#     def encode(self,sense_voice_output,text):
#         return {"ui":{"text":[sense_voice_output]}}
#
# WEB_DIRECTORY = "./js"

NODE_CLASS_MAPPINGS = {
    "VoiceRecorderNode":VoiceRecorderNode,
    "STTNode": STTNode,
    # "ShowTextNode":ShowTextNode
}
NODE_DISPLAY_NAME_MAPPINGS = {"VoiceRecorderNode": "voice record", "STTNode": "STT By SenseVoice"}

# ä¸»ç¨‹åºå…¥å£ ---------------------------------------------------------
# if __name__ == "__main__":
#     recorder = STTNode()
#     print("="*40)
#     print("è¯­éŸ³å½•åˆ¶ç³»ç»Ÿå·²å¯åŠ¨".center(40))
#     print("="*40)
#     recorder.generate('/home/fangg/other/save_voice/data_set/zh/TP225/300006.wav', 60)

def get_comfyui_root():
    # è·å–ä¸»æ¨¡å—ï¼ˆé€šå¸¸æ˜¯å¯åŠ¨è„šæœ¬ï¼Œå¦‚main.pyï¼‰
    main_module = sys.modules.get('__main__')
    if main_module and hasattr(main_module, '__file__'):
        main_path = os.path.abspath(main_module.__file__)
        root_dir = os.path.dirname(main_path)
        return root_dir
    else:
        # è‹¥æ— æ³•è·å–ä¸»æ¨¡å—è·¯å¾„ï¼Œå›é€€åˆ°å½“å‰å·¥ä½œç›®å½•
        return None